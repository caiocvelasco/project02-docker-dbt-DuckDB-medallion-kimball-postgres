{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Schemas:\n",
      "          schema_name\n",
      "0  information_schema\n",
      "1                main\n",
      "2          pg_catalog\n",
      "3              public\n",
      "4  information_schema\n",
      "5                main\n",
      "6          pg_catalog\n",
      "7  information_schema\n",
      "8                main\n",
      "9          pg_catalog\n",
      "\n",
      "Tables:\n",
      "  table_schema         table_name\n",
      "0         main  test_duckdb_model\n",
      "1       public  test_duckdb_model\n",
      "The 'bronze' schema does not exist.\n"
     ]
    }
   ],
   "source": [
    "import duckdb\n",
    "import pandas as pd\n",
    "\n",
    "# Path to your DuckDB database file\n",
    "duckdb_file_path = '/workspace/databases/dev.duckdb'\n",
    "\n",
    "# Use a context manager to handle the DuckDB connection\n",
    "with duckdb.connect(duckdb_file_path) as con:\n",
    "    # Query all schemas\n",
    "    query_schemas = \"SELECT schema_name FROM information_schema.schemata\"\n",
    "    schemas = con.execute(query_schemas).fetchdf()\n",
    "    \n",
    "    # Print the DataFrame of schemas\n",
    "    print(\"Schemas:\")\n",
    "    print(schemas)\n",
    "    \n",
    "    # Query all tables in each schema\n",
    "    query_tables = \"\"\"\n",
    "    SELECT table_schema, table_name \n",
    "    FROM information_schema.tables \n",
    "    WHERE table_schema IN (SELECT schema_name FROM information_schema.schemata)\n",
    "    \"\"\"\n",
    "    tables = con.execute(query_tables).fetchdf()\n",
    "    \n",
    "    # Print the DataFrame of tables\n",
    "    print(\"\\nTables:\")\n",
    "    print(tables)\n",
    "\n",
    "    # Check if the raw schema exists\n",
    "    schema_check_query = \"SELECT schema_name FROM information_schema.schemata WHERE schema_name = 'bronze'\"\n",
    "    schema_exists = con.execute(schema_check_query).fetchone()\n",
    "    if schema_exists:\n",
    "        # Query the table created by dbt\n",
    "        query = \"SELECT * FROM bronze.customers LIMIT 5\"\n",
    "        result = con.execute(query).fetchdf()\n",
    "\n",
    "        # Check if the result is not empty and print the DataFrame\n",
    "        if not result.empty:\n",
    "            print(result)\n",
    "        else:\n",
    "            print(\"No records found in the customers table.\")\n",
    "    else:\n",
    "        print(\"The 'bronze' schema does not exist.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a context manager to handle the DuckDB connection\n",
    "with duckdb.connect(duckdb_file_path) as con:\n",
    "    # Query to delete tables\n",
    "    # query_delete_bronze = \"DROP SCHEMA raw CASCADE;\"\n",
    "    query_delete_bronze = \"DROP SCHEMA bronze CASCADE;\"\n",
    "    # query_delete_silver = \"DROP SCHEMA silver CASCADE;\"\n",
    "    # query_delete_gold = \"DROP SCHEMA gold CASCADE;\"\n",
    "    con.execute(query_delete_bronze)\n",
    "    # con.execute(query_delete_silver)\n",
    "    # con.execute(query_delete_gold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import boto3\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error accessing bucket: An error occurred (InvalidAccessKeyId) when calling the ListObjectsV2 operation: The AWS Access Key Id you provided does not exist in our records.\n"
     ]
    }
   ],
   "source": [
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Fetch AWS credentials from environment variables\n",
    "s3_access_key_id = os.getenv('S3_ACCESS_KEY_ID')\n",
    "s3_secret_access_key = os.getenv('S3_SECRET_ACCESS_KEY')\n",
    "s3_region = os.getenv('S3_REGION')\n",
    "bucket_name = os.getenv('S3_BUCKET_NAME')\n",
    "\n",
    "# Initialize a session using boto3\n",
    "session = boto3.Session(\n",
    "    aws_access_key_id=s3_access_key_id,\n",
    "    aws_secret_access_key=s3_secret_access_key,\n",
    "    region_name=s3_region\n",
    ")\n",
    "\n",
    "# Initialize S3 client\n",
    "s3_client = session.client('s3')\n",
    "\n",
    "# Example: List objects in the bucket to verify access\n",
    "try:\n",
    "    response = s3_client.list_objects_v2(\n",
    "        Bucket=str(bucket_name)  # Ensure bucket_name is converted to string\n",
    "    )\n",
    "    # Print object keys if listing was successful\n",
    "    print(\"Objects in bucket:\")\n",
    "    for obj in response.get('Contents', []):\n",
    "        print(obj['Key'])\n",
    "except Exception as e:\n",
    "    print(f\"Error accessing bucket: {str(e)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
